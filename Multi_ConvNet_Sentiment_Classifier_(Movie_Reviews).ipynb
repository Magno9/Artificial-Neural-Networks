{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE SURE YOU USE \"myenv\" WHEN RUNNING THIS NOTEBOOK.\n",
    "\n",
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model # new!\n",
    "from keras.layers import Input, concatenate # new!\n",
    "from keras.layers import Dense, Dropout, Embedding, SpatialDropout1D, Conv1D, GlobalMaxPooling1D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output directory name:\n",
    "output_dir = 'model_output/multiconv'\n",
    "\n",
    "# training:\n",
    "epochs = 4\n",
    "batch_size = 128\n",
    "\n",
    "# vector-space embedding:\n",
    "n_dim = 64\n",
    "n_unique_words = 5000\n",
    "max_review_length = 400\n",
    "pad_type = trunc_type = 'pre'\n",
    "drop_embed = 0.2\n",
    "\n",
    "# convolutional layer architecture:\n",
    "n_conv_1 = n_conv_2 = n_conv_3 = 256\n",
    "k_conv_1 = 3\n",
    "k_conv_2 = 2\n",
    "k_conv_3 = 4\n",
    "\n",
    "# dense layer architecture:\n",
    "n_dense = 256\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_valid, y_valid) = imdb.load_data(num_words=n_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)\n",
    "X_valid = pad_sequences(X_valid, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Although sequential models constitute the vast majority of deep learning models, there are times when non-sequential \n",
    "architectures- which permit onfonote model-design posibilities and are often more complex- could be warranted. (Popular \n",
    "aspects of non-sequential models include having multiple model inputs or outputs- potentially at different levels within \n",
    "the architecture;e.g., a model could have an additional input or an additional output midway through the architecture- \n",
    "sharing the activations of a single layer with multiple other layers, and creating directly acyclic graphs.) In such \n",
    "situations, we can take advantage of the Keras 'functional' API, which makes use of the Model class instead of the \n",
    "Sequential models we've worked with so far in the book.\n",
    "As an example of a non-sequential architecture, we decided to riff on our highest performing sentiment classifier, the \n",
    "convolutional mode, to see if we could squeeze more juice out of the proverbial lemon. Our idea was to have three parallel \n",
    "streams of convolutional layers- each of which takes in word vectors from an Embedding() layer. As in our Convolutional \n",
    "Sentiment Classifier notebook, one of these streams eould have a filter length of three tokens. One of the others will have \n",
    "a filter of two- so it will specialize in learning word-vector pairs that appear to be relevant to classifying a film review\n",
    "as having positive or negative sentiment. The third convolutional stream will have a filter length of four tokens, so it \n",
    "will specialize in detecting relevant quadruplets of word meaning.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alex\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alex\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alex\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alex\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(max_review_length,), dtype='int16', name='input')\n",
    "\n",
    "# embedding:\n",
    "embedding_layer = Embedding(n_unique_words, n_dim, name='embedding')(input_layer)\n",
    "drop_embed_layer = SpatialDropout1D(drop_embed, name='drop_embed')(embedding_layer)\n",
    "\n",
    "# three parallel convolutional streams:\n",
    "conv_1 = Conv1D(n_conv_1, k_conv_1, activation='relu', name='conv_1')(drop_embed_layer)\n",
    "maxp_1 = GlobalMaxPooling1D(name='maxp_1')(conv_1)\n",
    "\n",
    "conv_2 = Conv1D(n_conv_2, k_conv_2, activation='relu', name='conv_2')(drop_embed_layer)\n",
    "maxp_2 = GlobalMaxPooling1D(name='maxp_2')(conv_2)\n",
    "\n",
    "conv_3 = Conv1D(n_conv_3, k_conv_3, activation='relu', name='conv_3')(drop_embed_layer)\n",
    "maxp_3 = GlobalMaxPooling1D(name='maxp_3')(conv_3)\n",
    "\n",
    "# concatenate the activations from the three streams:\n",
    "concat = concatenate([maxp_1, maxp_2, maxp_3])\n",
    "\n",
    "# dense hidden layers:\n",
    "dense_layer = Dense(n_dense, activation='relu', name='dense')(concat)\n",
    "drop_dense_layer = Dropout(dropout, name='drop_dense')(dense_layer)\n",
    "\n",
    "dense_2 = Dense(int(n_dense/4), activation='relu', name='dense_2')(drop_dense_layer)\n",
    "dropout_2 = Dropout(dropout, name='drop_dense_2')(dense_2)\n",
    "\n",
    "# sigmoid output layer:\n",
    "predictions = Dense(1, activation='sigmoid', name='output')(dropout_2)\n",
    "\n",
    "# create model:\n",
    "model = Model(input_layer, predictions)\n",
    "\n",
    "# I think this is all pretty straightforward but if you need an explanation go to page 254 of the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 400)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 400, 64)      320000      input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "drop_embed (SpatialDropout1D)   (None, 400, 64)      0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv1D)                 (None, 398, 256)     49408       drop_embed[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv1D)                 (None, 399, 256)     33024       drop_embed[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv1D)                 (None, 397, 256)     65792       drop_embed[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "maxp_1 (GlobalMaxPooling1D)     (None, 256)          0           conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "maxp_2 (GlobalMaxPooling1D)     (None, 256)          0           conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "maxp_3 (GlobalMaxPooling1D)     (None, 256)          0           conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 768)          0           maxp_1[0][0]                     \n",
      "                                                                 maxp_2[0][0]                     \n",
      "                                                                 maxp_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          196864      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "drop_dense (Dropout)            (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           16448       drop_dense[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "drop_dense_2 (Dropout)          (None, 64)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            65          drop_dense_2[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 681,601\n",
      "Trainable params: 681,601\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alex\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alex\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alex\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+'/weights.{epoch:02d}.hdf5')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alex\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alex\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alex\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/4\n",
      "WARNING:tensorflow:From C:\\Users\\alex\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alex\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alex\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alex\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alex\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "25000/25000 [==============================] - 302s 12ms/step - loss: 0.4962 - acc: 0.7311 - val_loss: 0.2935 - val_acc: 0.8782\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 345s 14ms/step - loss: 0.2537 - acc: 0.8993 - val_loss: 0.2628 - val_acc: 0.8932\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 417s 17ms/step - loss: 0.1740 - acc: 0.9361 - val_loss: 0.2641 - val_acc: 0.8942\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 7498s 300ms/step - loss: 0.1229 - acc: 0.9571 - val_loss: 0.3018 - val_acc: 0.8908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23c6bf7ce48>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_valid, y_valid),\n",
    "          callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(output_dir+'/weights.02.hdf5')\n",
    "# Something a bit weird happened here. Not sure how, but epoch 3 has a higher accuracy than epoch 2 despite having a higher \n",
    "# loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat, bins=100)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'96.15'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:0.2f}\".format(roc_auc_score(y_valid, y_hat)*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the best sentiment classifier out of all of the ones trained, just narrowly beating the regular Sequential() \n",
    "# convolutional classifier. The authors of DLI (Deep Learning Illustrated) hypothesize that if the IMDB dataset had been \n",
    "# much larger, the Bi-LSTM architectures would have outperformed the convolutional ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
